\chapter{Conclusion}
\label{ch:conclusion}

% This proof of concept was developed mainly in January 2025 for a manuscript to be submitted to the US-Europe Air Transportation Research \& Development Symposium (ATRDS).

In \cref{ch:atrds}, we examined a simplified problem formulation to understand how we would begin to go about bridging the gap between purely data-driven analysis and existing domain knowledge. To go beyond this guiding example, there are at least a few natural directions for further extension and study.

The first is to go further in what we are hoping to understanding from an air traffic management perspective. In particular, we note that we have not yet considered in depth how air traffic managers are meant to interact with the simulation or any other part of the overall process, and so \cref{app:atm} will focus on bridging that gap. A second idea is gaining a better understanding of how exactly we can quantify risk, especially in a more complex network scenario where it is less immediately obvious how to construct a single exceedance probability, which we will discuss further in \cref{app:risk}. This will enable more flexibility in how we interact with the notion of risk and failure in our data-driven approach. Third, in \cref{app:shrinkage}, we will continue along the previously introduced concept of robustly combining information when the quantity or quality of data is less than ideal. 

It is important to stress a couple points here, most importantly, that these directions are far from comprehensive. As even the problem itself is not particularly well-defined without some work, there are many possible directions to further investigate, some of which we will note in this chapter as well.


\section{Future Work}

\subsection{Extending the Guiding Case Study} For our guiding case study specifically, we plan to extend the method from a single airport study to a larger network, so that we can capture a wider range of latent parameters than just a single mean service time. We also note that we run into some limitations because of the simplifying choices made. For example, choosing simple threshold-based structures for $\fvn$ and $\gvn$ may not work as well when working with more complex problems, and we plan to investigate more general mixtures, in a similar idea to what is studied in \cite{flowgmm2019}. Along similar lines, introducing more direct support for actions, similarly to what is implemented for a different non-stochastic simulator in \cite{michael_peng_probing_2024}, is another direction for future study. Finally, we could attempt to relax the requirement of having access to both likelihoods and gradients from the simulator, and also introduce explicit methods for working with more limited data, by considering other methods such as \cite{parashar2024failure, maurya2016, dawson2024breaking}.

\subsection{Learning Surrogate Models}

For completeness, we will also consider dropping the assumption that we already know some part of underlying structure of the true data distribution (e.g. through simulation), and working the problem of working directly with the available data. In other words, this would be only looking at the case of $\rw\leftrightarrow \rx$. Here, our goal is to learn some structure for our paired observations in an unsupervised manner. For example, the originally considered idea of directly using a diffusion model to generate novel weather examples that correspond to failure flight days would fall under this category. On its own, this can serve as a baseline to compare results against, though it may be difficult to learn anything useful if we do not have enough data. Additionally, the results would be less interpretable than an approach that specifies more of the underlying model, since we do not necessarily learn a latent space that represents anything meaningful. However, learning such a surrogate model may still be useful as a component of other approaches for failure modeling and prediction.

\subsection{Actively Generating Failures} 

Here, we will assume that we are working with a $\rw\to \rz\to \rx$ hierarchical model, where, in the language of the air traffic problem, $\rx$ are the observed delays, $\rz$ are simulation parameters such as mean service and turnaround times at individual airports, and $\rw$ are weather conditions. The problem of generating failure conditions can be framed as finding values of $w$ or $z$ such that $\PP(x\in \Omega_f\given w)>\pi_f$ or $\PP(x\in\Omega_f\given z)>\pi_f$, respectively, where $\Omega_f$ is some set of values $x$ that we consider failures (e.g. delays above fifteen minutes), and $\pi_f\in [0,1]$ is some threshold for failure risk. In other words, we want to find values $w$ or $z$ such that $x$ is likely to fall in $\Omega$.

The problem of finding values of $z$ only, which, because of the conditional independencies, restricts us to the $\rz \to \rx$ part of the model, is well-studied, so in our case this may be just applying existing methods to find failure inputs for whatever air traffic simulator we are interested in. When introducing $w$, the problem is a bit more complicated if we also need to learn $\rw\to\rz$. Since this part is often more difficult to model satisfactorily, learning a black-box surrogate model for it may be preferable, but does sacrifice some interpretability of results.

Now comes the ``active'' part. What happens if the the simulation is allowed to change after each new failure we discover? Naturally, training and planning on the part of air traffic managers is a plausible scenario in which we could enact a failure discovery and repair loop. For example, we could consider a simulation in which the traffic managers are able to use their current knowledge to control some parts of it, such as by imposing traffic management initiatives. Then, in the current iteration, we might attempt to generate adversarial conditions that they have trouble dealing with. However, if these difficult conditions are reduced to normal conditions because of planning around the observed failure mode to mitigate future incidents, our strategy for generating failure conditions would likely have to adjust in the next iteration as well. This sort of alternating adversarial optimization formulation is one we have not yet considered, but it is one that is both interesting and practically relevant. Some related work in the failure prediction and repair cycle, from a slightly different perspective, can be found in \cite{dawson2024breaking, 10925872, DBLP:journals/corr/abs-2203-02038}.
